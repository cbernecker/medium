{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# imports\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "# transforms\r\n",
    "transform = transforms.Compose(\r\n",
    "    [transforms.ToTensor(),\r\n",
    "    transforms.Normalize((0.5,), (0.5,))])\r\n",
    "\r\n",
    "# batch_size\r\n",
    "batch_size = 8\r\n",
    "\r\n",
    "# datasets\r\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=transform)\r\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\r\n",
    "    download=True,\r\n",
    "    train=False,\r\n",
    "    transform=transform)\r\n",
    "\r\n",
    "# dataloaders\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\r\n",
    "                                        shuffle=True, num_workers=2)\r\n",
    "\r\n",
    "\r\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\r\n",
    "                                        shuffle=False, num_workers=2)\r\n",
    "\r\n",
    "# constant for classes\r\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Net(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\r\n",
    "        self.pool = nn.MaxPool2d(2, 2)\r\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\r\n",
    "        self.fc2 = nn.Linear(120, 84)\r\n",
    "        self.fc3 = nn.Linear(84, 10)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pool(F.relu(self.conv1(x)))\r\n",
    "        x = self.pool(F.relu(self.conv2(x)))\r\n",
    "        x = x.view(-1, 16 * 4 * 4)\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "net = Net()\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "import seaborn as sn\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "def createConfusionMatrix(loader):\r\n",
    "    y_pred = [] # save predction\r\n",
    "    y_true = [] # save ground truth\r\n",
    "\r\n",
    "    # iterate over data\r\n",
    "    for inputs, labels in loader:\r\n",
    "        output = net(inputs)  # Feed Network\r\n",
    "\r\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\r\n",
    "        y_pred.extend(output)  # save prediction\r\n",
    "\r\n",
    "        labels = labels.data.cpu().numpy()\r\n",
    "        y_true.extend(labels)  # save ground truth\r\n",
    "\r\n",
    "    # constant for classes\r\n",
    "    classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\r\n",
    "\r\n",
    "    # Build confusion matrix\r\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\r\n",
    "    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i for i in classes],\r\n",
    "                         columns=[i for i in classes])\r\n",
    "    # Create Heatmap\r\n",
    "    plt.figure(figsize=(12, 7))    \r\n",
    "    return sn.heatmap(df_cm, annot=True).get_figure()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "running_loss = 0.0\r\n",
    "accuracy = 0\r\n",
    "epochs = 15\r\n",
    "\r\n",
    "# tensorboard file\r\n",
    "writer = SummaryWriter('runs/fashion_mnist')\r\n",
    "\r\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\r\n",
    "    print('Epoch-{0} lr: {1}'.format(epoch + 1, optimizer.param_groups[0]['lr']))\r\n",
    "    for i, data in enumerate(trainloader, 0):\r\n",
    "        inputs, labels = data # get the inputs; data is a list of [inputs, labels]\r\n",
    "        optimizer.zero_grad() # zero the parameter gradients\r\n",
    "        \r\n",
    "        outputs = net(inputs) # forward\r\n",
    "        loss = criterion(outputs, labels) # calculate loss\r\n",
    "        loss.backward() # backward loss\r\n",
    "        optimizer.step() # optimize gradients\r\n",
    "\r\n",
    "        running_loss += loss.item() # save loss\r\n",
    "        _, preds = torch.max(outputs, 1) # save prediction\r\n",
    "        accuracy += torch.sum(preds == labels.data) # save accuracy\r\n",
    "        \r\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...           \r\n",
    "            steps = epoch * len(trainloader) + i # calculate steps \r\n",
    "            batch = i*batch_size # calculate batch \r\n",
    "            print(\"Training loss {:.3} Accuracy {:.3} Steps: {}\".format(running_loss / batch, accuracy/batch, steps))\r\n",
    "            \r\n",
    "            # Save accuracy and loss to Tensorboard\r\n",
    "            writer.add_scalar('Training loss by steps', running_loss / batch, steps)\r\n",
    "            writer.add_scalar('Training accuracy by steps', accuracy / batch, steps)\r\n",
    "            \r\n",
    "            \r\n",
    "    print(\"Accuracy: {}/{} ({:.3} %) Loss: {:.3}\".format(accuracy, len(trainloader), 100. * accuracy / len(trainloader.dataset), running_loss / len(trainloader.dataset)))\r\n",
    "    \r\n",
    "    # Save confusion matrix to Tensorboard\r\n",
    "    writer.add_figure(\"Confusion matrix\", createConfusionMatrix(trainloader), epoch)\r\n",
    "    \r\n",
    "    running_loss = 0.0\r\n",
    "    accuracy = 0\r\n",
    "    \r\n",
    "print('Finished Training')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit"
  },
  "interpreter": {
   "hash": "1322ea8e27b4cc5d06c2ce29c987a7b3e0f46ef86fd01f574437e5c3490ec2b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
