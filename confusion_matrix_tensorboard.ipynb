{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# imports\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "# transforms\r\n",
    "transform = transforms.Compose(\r\n",
    "    [transforms.ToTensor(),\r\n",
    "    transforms.Normalize((0.5,), (0.5,))])\r\n",
    "\r\n",
    "# batch_size\r\n",
    "batch_size = 8\r\n",
    "\r\n",
    "# datasets\r\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=transform)\r\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\r\n",
    "    download=True,\r\n",
    "    train=False,\r\n",
    "    transform=transform)\r\n",
    "\r\n",
    "# dataloaders\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\r\n",
    "                                        shuffle=True, num_workers=2)\r\n",
    "\r\n",
    "\r\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\r\n",
    "                                        shuffle=False, num_workers=2)\r\n",
    "\r\n",
    "# constant for classes\r\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "In C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "26422272it [00:04, 5302933.67it/s]                              \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/29515 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "29696it [00:00, 1246987.02it/s]          \n",
      "  0%|          | 0/4422102 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "4422656it [00:00, 4903053.82it/s]                             \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "6144it [00:00, 1501037.03it/s]          "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "C:\\Users\\ChristianBernecker\\AppData\\Roaming\\Python\\Python36\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Net(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\r\n",
    "        self.pool = nn.MaxPool2d(2, 2)\r\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\r\n",
    "        self.fc2 = nn.Linear(120, 84)\r\n",
    "        self.fc3 = nn.Linear(84, 10)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pool(F.relu(self.conv1(x)))\r\n",
    "        x = self.pool(F.relu(self.conv2(x)))\r\n",
    "        x = x.view(-1, 16 * 4 * 4)\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "net = Net()\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "import seaborn as sn\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "def createConfusionMatrix(loader):\r\n",
    "    y_pred = [] # save predction\r\n",
    "    y_true = [] # save ground truth\r\n",
    "\r\n",
    "    # iterate over data\r\n",
    "    for inputs, labels in loader:\r\n",
    "        output = net(inputs)  # Feed Network\r\n",
    "\r\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\r\n",
    "        y_pred.extend(output)  # save prediction\r\n",
    "\r\n",
    "        labels = labels.data.cpu().numpy()\r\n",
    "        y_true.extend(labels)  # save ground truth\r\n",
    "\r\n",
    "    # constant for classes\r\n",
    "    classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\r\n",
    "\r\n",
    "    # Build confusion matrix\r\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\r\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) * 10, index=[i for i in classes],\r\n",
    "                         columns=[i for i in classes])\r\n",
    "    plt.figure(figsize=(12, 7))    \r\n",
    "    return sn.heatmap(df_cm, annot=True).get_figure()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "running_loss = 0.0\r\n",
    "accuracy = 0\r\n",
    "epochs = 15\r\n",
    "\r\n",
    "# tensorboard file\r\n",
    "writer = SummaryWriter('runs/fashion_mnist')\r\n",
    "\r\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\r\n",
    "    print('Epoch-{0} lr: {1}'.format(epoch + 1, optimizer.param_groups[0]['lr']))\r\n",
    "    for i, data in enumerate(trainloader, 0):\r\n",
    "        inputs, labels = data # get the inputs; data is a list of [inputs, labels]\r\n",
    "        optimizer.zero_grad() # zero the parameter gradients\r\n",
    "        \r\n",
    "        outputs = net(inputs) # forward\r\n",
    "        loss = criterion(outputs, labels) # calculate loss\r\n",
    "        loss.backward() # backward loss\r\n",
    "        optimizer.step() # optimize gradients\r\n",
    "\r\n",
    "        running_loss += loss.item() # save loss\r\n",
    "        _, preds = torch.max(outputs, 1) # save prediction\r\n",
    "        accuracy += torch.sum(preds == labels.data) # save accuracy\r\n",
    "        \r\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...           \r\n",
    "            steps = epoch * len(trainloader) + i # calculate steps \r\n",
    "            batch = i*batch_size # calculate batch \r\n",
    "            print(\"Training loss {:.3} Accuracy {:.3} Steps: {}\".format(running_loss / batch, accuracy/batch, steps))\r\n",
    "            \r\n",
    "            # Save accuracy and loss to Tensorboard\r\n",
    "            writer.add_scalar('Training loss by steps', running_loss / batch, steps)\r\n",
    "            writer.add_scalar('Training accuracy by steps', accuracy / batch, steps)\r\n",
    "            \r\n",
    "            \r\n",
    "    print(\"Accuracy: {}/{} ({:.3} %) Loss: {:.3}\".format(accuracy, len(trainloader), 100. * accuracy / len(trainloader.dataset), running_loss / len(trainloader.dataset)))\r\n",
    "    \r\n",
    "    # Save confusion matrix to Tensorboard\r\n",
    "    writer.add_figure(\"Confusion matrix\", createConfusionMatrix(trainloader), epoch)\r\n",
    "    \r\n",
    "    running_loss = 0.0\r\n",
    "    accuracy = 0\r\n",
    "    \r\n",
    "print('Finished Training')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch-1 lr: 0.001\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "C:\\Users\\ChristianBernecker\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\autograd\\__init__.py:149: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:115.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss 0.19 Accuracy 0.454 Steps: 999\n",
      "Training loss 0.141 Accuracy 0.584 Steps: 1999\n",
      "Training loss 0.12 Accuracy 0.642 Steps: 2999\n",
      "Training loss 0.108 Accuracy 0.676 Steps: 3999\n",
      "Training loss 0.1 Accuracy 0.7 Steps: 4999\n",
      "Training loss 0.0941 Accuracy 0.718 Steps: 5999\n",
      "Training loss 0.0894 Accuracy 0.732 Steps: 6999\n",
      "Accuracy: 44276/7500 (73.8 %) Loss: 0.0874\n",
      "Epoch-2 lr: 0.001\n",
      "Training loss 0.057 Accuracy 0.833 Steps: 8499\n",
      "Training loss 0.0563 Accuracy 0.834 Steps: 9499\n",
      "Training loss 0.0551 Accuracy 0.837 Steps: 10499\n",
      "Training loss 0.0544 Accuracy 0.84 Steps: 11499\n",
      "Training loss 0.0536 Accuracy 0.843 Steps: 12499\n",
      "Training loss 0.0532 Accuracy 0.844 Steps: 13499\n",
      "Training loss 0.0524 Accuracy 0.846 Steps: 14499\n",
      "Accuracy: 50841/7500 (84.7 %) Loss: 0.052\n",
      "Epoch-3 lr: 0.001\n",
      "Training loss 0.0469 Accuracy 0.864 Steps: 15999\n",
      "Training loss 0.0471 Accuracy 0.863 Steps: 16999\n",
      "Training loss 0.0466 Accuracy 0.864 Steps: 17999\n",
      "Training loss 0.0459 Accuracy 0.866 Steps: 18999\n",
      "Training loss 0.0457 Accuracy 0.867 Steps: 19999\n",
      "Training loss 0.0452 Accuracy 0.869 Steps: 20999\n",
      "Training loss 0.0449 Accuracy 0.869 Steps: 21999\n",
      "Accuracy: 52117/7500 (86.9 %) Loss: 0.0449\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit"
  },
  "interpreter": {
   "hash": "1322ea8e27b4cc5d06c2ce29c987a7b3e0f46ef86fd01f574437e5c3490ec2b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}