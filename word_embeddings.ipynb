{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search with Word Embeddings using BERT Transformers\n",
    "\n",
    "Explore the world of semantic similarity search using pretrained word embeddings with BERT Transformers in this code snippet. The example demonstrates how to compute and compare sentence embeddings, enabling semantic search for related content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://cbernecker%40munichre.com:****@mrartiemea.jfrog.io/artifactory/api/pypi/dragonfly-pypi-virtual/simpleNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'C:\\Development\\medium\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: sentence-transformers in c:\\development\\medium\\.venv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\development\\medium\\.venv\\lib\\site-packages (from sentence-transformers) (4.38.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\development\\medium\\.venv\\lib\\site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: tqdm in c:\\development\\medium\\.venv\\lib\\site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: numpy in c:\\development\\medium\\.venv\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\development\\medium\\.venv\\lib\\site-packages (from sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\development\\medium\\.venv\\lib\\site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: Pillow in c:\\development\\medium\\.venv\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: scipy in c:\\development\\medium\\.venv\\lib\\site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\development\\medium\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\development\\medium\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\development\\medium\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: requests in c:\\development\\medium\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in c:\\development\\medium\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\development\\medium\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\development\\medium\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: networkx in c:\\development\\medium\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: sympy in c:\\development\\medium\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: colorama in c:\\development\\medium\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\development\\medium\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\development\\medium\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\development\\medium\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\development\\medium\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\development\\medium\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\development\\medium\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\development\\medium\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\development\\medium\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\development\\medium\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\development\\medium\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\development\\medium\\.venv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Snippet 1: Sentence Embeddings and Similarity Calculation\n",
    "In summary, this code snippet demonstrates the process of using a pretrained BERT model to convert sentences into embeddings and then calculating the cosine similarity between pairs of sentences. The resulting similarity scores provide a quantitative measure of how closely related or similar the pairs of sentences are in a semantic context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Snippet 2: Semantic Search for Similar Queries\n",
    "\n",
    "In summary, Code Snippet 2 showcases a hypothetical scenario where previously computed sentence embeddings are used for semantic search. The code demonstrates how to find sentences similar to a set of query sentences based on cosine similarity. This type of semantic search can be valuable in applications where you want to retrieve content related to specific queries, such as finding relevant documents or articles based on user-input queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# We use cosine-similarity and torch.topk to find the highest 5 scores\u001b[39;00m\n\u001b[0;32m     27\u001b[0m cos_scores \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mcos_sim(query_embedding, corpus_embeddings)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 28\u001b[0m top_results \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtopk(cos_scores, k\u001b[38;5;241m=\u001b[39mtop_k)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m======================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery:\u001b[39m\u001b[38;5;124m\"\u001b[39m, query)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "#import torch\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['is tiktok getting banned.',\n",
    "          'is tiktok shutting down.',\n",
    "          'is tiktok banned in us.',\n",
    "          'is tiktok getting deleted.',\n",
    "          'is tiktok a competitor for instagram.',\n",
    "          'is instagram a useful app',\n",
    "          'something unrelevant'\n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['is tiktok']\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(7, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: {:.4f})\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "undefined.-xfrozen_modules=off"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
