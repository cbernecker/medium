{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Code a Simple Question Answering System with OpenAI\n",
    "This hands-on project will guide you through the process of programming, covering essential steps such as defining prompt templates, integrating OPEN AI as language model, and implementing retrieval mechanisms to fetch information. By the end of the section, you'll have gained practical experience in building a simple yet effective question-answering solution, offering valuable insights into the mechanics of this exciting field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain lxml chromadb sentence-transformers ctransformers openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Visit Wikipedia and retrieve the [Wikipedia page for the Porsche 911](https://en.wikipedia.org/wiki/Porsche_911). In this simplified example, we are only loading a single page, but in practice, you have the capability to load multiple pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader 44 files\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import HTMLHeaderTextSplitter\n",
    "\n",
    "file_path= r'.\\data\\Wikipedia 911\\Porsche 911 - Wikipedia.html'\n",
    "file1 = open(file_path, encoding='utf-8')\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "    (\"h4\", \"Header 4\"),\n",
    "    (\"h5\", \"Header 5\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on, return_each_element=None)\n",
    "html_header_splits = html_splitter.split_text(file1.read())\n",
    "print(\"Loader {} files\".format(len(html_header_splits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents and save them into a vector database\n",
    "In the subsequent phase, we divide the HTML page into subsections according to the headers. Feel free to employ alternative criteria for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "# Define the Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 384,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "#Create a split of the document using the text splitter\n",
    "splits = text_splitter.split_documents(html_header_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Store embeddings in a vector database.\n",
    "Next, we save all the data as word embeddings in ChromaDB. The embedding function() utilizes a transformer model loaded from the SBert library. You have the flexibility to experiment with various models. For reference, check the available options in the Pretrained Models section of the Sentence-Transformers documentation at [sbert.net](https://www.sbert.net/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedd the Splits\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create the vector store\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding_function, #embedding,\n",
    ")\n",
    "\n",
    "print(f'{vectordb._collection.count()} Embeddings are loaded in the Vector Database')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the OpenAI Model\n",
    "\n",
    "Load a OpenAI Model to answer the question. This can take a few minutes because the model will be downloaded the first time. \n",
    "\n",
    "Make sure you have and [OpenAI Account](https://platform.openai.com/assistants) and you created an API-Key. Make sure you\n",
    "create an ENV variable called \n",
    "\n",
    "- OPENAI_API_KEY\n",
    "\n",
    "with the created API-Key to use OpenAI. More information [here](https://platform.openai.com/docs/quickstart?context=python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm=OpenAI()\n",
    "\n",
    "def setupTheQAChain(modelType = \"gpt-3.5-turbo\"):\n",
    "\n",
    "    print(\"Using model: {}\".format(modelType))\n",
    "\n",
    "    llm = ChatOpenAI(model_name=modelType, temperature=0)\n",
    "\n",
    "    template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible.  \n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=vectordb.as_retriever(search_kwargs={'k': 7}),\n",
    "        return_source_documents=True,\n",
    "        chain_type='stuff',\n",
    "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    "    )\n",
    "\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's bring everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: gpt-3.5-turbo\n",
      "Query: Which Porsche has the highest top speed? \n",
      "Results The Porsche 911 GT1 has the highest top speed of 310 km/h (193 mph). \n",
      "Source: [Document(page_content='Unlike the previous GT2 versions, this car is fitted with a 7-speed PDK transmission to handle the excessive torque produced from the engine. Porsche claims that this car will accelerate from 0 to 60\\xa0mph (97\\xa0km/h) in 2.7\\xa0seconds, and has a top speed of 340\\xa0km/h (210\\xa0mph).', metadata={'Header 1': 'Porsche 911', 'Header 2': 'Water-cooled engines (1998–present)[edit]', 'Header 3': '991 Series (2011 – 2019)[edit]', 'Header 4': '991 GT2 RS[edit]'}), Document(page_content='magazine tested the 997 GT3 and recorded a 0–100\\xa0km/h (62\\xa0mph) of 3.9\\xa0seconds and a top speed of 312\\xa0km/h (194\\xa0mph). It was at that time crowned \"the best handling car in America\" by Motor Trend.[citation needed]', metadata={'Header 1': 'Porsche 911', 'Header 2': 'Water-cooled engines (1998–present)[edit]', 'Header 3': '997 (2004–2013)[edit]', 'Header 4': '997 GT3[edit]'}), Document(page_content=\"The 911 GT3 was added to the 997 lineage on 23 February 2006. Performance figures include a 0–100 kilometres per hour (0–62\\xa0mph) acceleration time of 4.1\\xa0seconds and a top speed of 310\\xa0km/h (193\\xa0mph), almost as fast as the Turbo. Porsche's factory reports were proven to be conservative about the performance of the car; Excellence magazine tested the 997 GT3 and recorded a\", metadata={'Header 1': 'Porsche 911', 'Header 2': 'Water-cooled engines (1998–present)[edit]', 'Header 3': '997 (2004–2013)[edit]', 'Header 4': '997 GT3[edit]'}), Document(page_content='3.2.7Carrera GTS  \\n3.2.8Speedster  \\n3.3991 Series (2011 – 2019)  \\n3.3.1991 GT3  \\n3.3.2991 GT3 RS  \\n3.3.3911 R  \\n3.3.4991 GT2 RS  \\n3.3.5Speedster (2019)  \\n3.4992 Series (2019–present)  \\n4911 GT1  \\n5Awards  \\n6Notes  \\n7References  \\n8Further reading  \\n9External links  \\nToggle the table of contents Porsche 911'), Document(page_content='The Porsche 911 GT1 is a race car that was developed in 1996 for the GT1 class in the 24 Hours of Le Mans. In order to qualify for GT racing, 25 road-going models were built to achieve type homologation. The engine in the GT1 is rated at 608\\xa0PS (447\\xa0kW; 600\\xa0hp) (544\\xa0PS (400\\xa0kW; 537\\xa0hp) for the road version) and accelerated from 0–97\\xa0km/h in 3.3 seconds. The top speed stood at', metadata={'Header 1': 'Porsche 911', 'Header 2': '911 GT1[edit]'}), Document(page_content='Motor Trend tested a 2008 Porsche 911 GT2 and found the 0–60\\xa0mph (97\\xa0km/h) acceleration time at 3.4\\xa0seconds, and 11.4\\xa0seconds at 127.9 miles per hour (205.8\\xa0km/h) for the quarter mile. The GT2 also recorded a braking distance from 60 to 0 miles per hour (97 to 0\\xa0km/h) of 98 feet (30\\xa0m) and recorded 1.10g lateral grip.[45] The GT2 made an appearance on Top Gear, where it had a lap', metadata={'Header 1': 'Porsche 911', 'Header 2': 'Water-cooled engines (1998–present)[edit]', 'Header 3': '997 (2004–2013)[edit]', 'Header 4': '997 GT2[edit]'}), Document(page_content='\"100 Coolest Cars\". Motor Trend chose the Porsche 911 Carrera S as its Best Driver\\'s Car for 2012.[73] It also won \"World Performance Car Of The Year\" in 2014.[74]', metadata={'Header 1': 'Porsche 911', 'Header 2': 'Awards[edit]'})]\n"
     ]
    }
   ],
   "source": [
    "qa_chain = setupTheQAChain()\n",
    "results = qa_chain.invoke({\"query\": \"Which Porsche has the highest top speed?\" })\n",
    "print('Query: {} \\nResults {} \\nSource: {}'.format(results['query'], results['result'], results['source_documents']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "undefined.-xfrozen_modules=off"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
