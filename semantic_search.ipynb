{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Code a Semantic Search\n",
    "In this example we use vector embeddings to convert text data related to the Porsche 911 Wikipedia page into numerical representations. Ingest these embeddings into a vector database, enabling users to perform similarity search and discover related content based on the Porsche 911 Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain lxml chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Visit Wikipedia and retrieve the [Wikipedia page for the Porsche 911](https://en.wikipedia.org/wiki/Porsche_911). In this simplified example, we are only loading a single page, but in practice, you have the capability to load multiple pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader 44 files\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import HTMLHeaderTextSplitter\n",
    "\n",
    "# Load the dataset\n",
    "file_path= \".\\data\\Wikipedia 911\\Porsche 911 - Wikipedia.html\"\n",
    "file1 = open(file_path, encoding='utf-8')\n",
    "\n",
    "# Split\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "    (\"h4\", \"Header 4\"),\n",
    "    (\"h5\", \"Header 5\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(file1.read())\n",
    "print(\"Loader {} files\".format(len(html_header_splits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents and save them into a vector database\n",
    "In the subsequent phase, we divide the HTML page into subsections according to the headers. Feel free to employ alternative criteria for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Text Splitter \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "\n",
    "#Create a split of the document using the text splitter\n",
    "splits = text_splitter.split_documents(html_header_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Store embeddings in a vector database.\n",
    "Next, we save all the data as word embeddings in ChromaDB. The embedding function() utilizes a transformer model loaded from the SBert library. You have the flexibility to experiment with various models. For reference, check the available options in the Pretrained Models section of the Sentence-Transformers documentation at [sbert.net](https://www.sbert.net/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 Embeddings are loaded in the Vector Database\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "# The Word Embeddings function from SBert\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create the vector store\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,             # documents\n",
    "    embedding=embedding_function, # embeddings\n",
    ")\n",
    "\n",
    "print(f'{vectordb._collection.count()} Embeddings are loaded in the Vector Database')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Search\n",
    "Here we bring everything together to find the section in a document that can answer our question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 911 GT3 was added to the 997 lineage on 23 February 2006. Performance figures include a 0–100 kilometres per hour (0–62 mph) acceleration time of 4.1 seconds and a top speed of 310 km/h (193 mph), almost as fast as the Turbo. Porsche's factory re\n",
      "Score: 0.5464710815783989\n",
      "{'Header 1': 'Porsche 911', 'Header 2': 'Water-cooled engines (1998–present)[edit]', 'Header 3': '997 (2004–2013)[edit]', 'Header 4': '997 GT3[edit]'}\n",
      "================================\n",
      "The Porsche 911 GT1 is a race car that was developed in 1996 for the GT1 class in the 24 Hours of Le Mans. In order to qualify for GT racing, 25 road-going models were built to achieve type homologation. The engine in the GT1 is rated at 608 PS (447 \n",
      "Score: 0.5167648869298593\n",
      "{'Header 1': 'Porsche 911', 'Header 2': '911 GT1[edit]'}\n",
      "================================\n",
      "In 2016, Porsche unveiled a limited production 911 R based on the GT3 RS. Production was limited to 991 units worldwide.[62] It has an overall weight of 1,370 kg (3,020 lb), a high-revving 4.0 L six-cylinder naturally aspirated engine from the 991 GT\n",
      "Score: 0.4830588299170906\n",
      "{'Header 1': 'Porsche 911', 'Header 2': 'Water-cooled engines (1998–present)[edit]', 'Header 3': '991 Series (2011 – 2019)[edit]', 'Header 4': '911 R[edit]'}\n",
      "================================\n",
      "In 2011, Porsche added a new 911 Speedster in a limited series of only 356 units to the 997 lineage, the number of cars produced recalling the iconic car of the 1950s. It was the third 911 Speedster produced, the other two being from the 930 and 964 \n",
      "Score: 0.4586515899444319\n",
      "{'Header 1': 'Porsche 911', 'Header 2': 'Water-cooled engines (1998–present)[edit]', 'Header 3': '997 (2004–2013)[edit]', 'Header 4': 'Speedster[edit]'}\n",
      "================================\n",
      "The high-performance GT2 version made a return to the 991 lineage but now as an RS variant only with no standard variant being produced, unlike the previous generations. It was initially unveiled at the 2017 E3 along with the announcement of the Forz\n",
      "Score: 0.45627977604448133\n",
      "{'Header 1': 'Porsche 911', 'Header 2': 'Water-cooled engines (1998–present)[edit]', 'Header 3': '991 Series (2011 – 2019)[edit]', 'Header 4': '991 GT2 RS[edit]'}\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "# Question\n",
    "question = \"Which Porsche has the best top speed?\"\n",
    "\n",
    "# Sematic Similarity search with cosine distance\n",
    "docs_similarity = vectordb.similarity_search_with_relevance_scores(question, k=5)\n",
    "\n",
    "# helper to make the answer more readable\n",
    "def make_docs_readable(docs, truncate = None):  \n",
    "    for doc, score in docs:\n",
    "        print(doc.page_content[:truncate])\n",
    "        print(\"Score: {}\".format(score))\n",
    "        print(doc.metadata)\n",
    "        print(\"================================\")\n",
    "\n",
    "make_docs_readable(docs_similarity, truncate=250) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "undefined.-xfrozen_modules=off"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
