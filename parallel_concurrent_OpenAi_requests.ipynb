{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Scoring with OpenAI \n",
    "You can use a similar multithreading approach to make batch requests to the OpenAI API's completions endpoint. This can be particularly useful if you need to process a large number of requests in parallel to improve throughput and reduce waiting times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install necessary packages\n",
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os \n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client.api_key = os.environ[\"OPENAI_API_KEY\"] #'your-api-key-here'\n",
    "\n",
    "# Function to make a request to the OpenAI API\n",
    "@multithreaded(max_workers=5)\n",
    "def get_completion(prompt):\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=1.1\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# List of prompts to process\n",
    "prompts = [\n",
    "    \"Tell me a joke.\",\n",
    "    \"What's the weather like today?\",\n",
    "    \"Explain the theory of relativity.\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Write a short story about a dragon.\",\n",
    "    \"Translate 'Hello' to Spanish.\",\n",
    "    \"What's the tallest mountain in the world?\",\n",
    "    \"Who was Albert Einstein?\",\n",
    "    \"Give me a recipe for chocolate cake.\",\n",
    "    \"What are the benefits of meditation?\"\n",
    "]\n",
    "\n",
    "# Using the decorated function to process prompts in parallel\n",
    "start_time = time.time()\n",
    "responses = get_completion(prompts)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Responses:\", responses)\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
